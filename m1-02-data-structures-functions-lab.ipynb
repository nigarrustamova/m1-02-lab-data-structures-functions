{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2b7440-5c4d-4558-b930-70e5b948590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50acbac1-167c-4a65-82bb-dd8ca917b28e",
   "metadata": {},
   "source": [
    "# Task 1: Build a raw log dataset\n",
    "Write code that generates a list of dictionaries representing support tickets. Each dictionary should include the fields described in the setup. Include at least 200 entries so that summaries are meaningful. Introduce realistic variation, such as a few categories that appear more frequently and occasional missing or malformed resolution_minutes values to simulate dirty data.\n",
    "\n",
    "You are expected to write the generator logic yourself. Keep it readable and explain the logic in short markdown notes where necessary. After generating the list, print the first five entries and the total count to validate the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2844e2-2f55-4a7c-b38e-2bddaaedde00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 200\n",
      "First 5 entries: [{'ticket_id': 1000, 'customer_id': 108, 'category': 'technical ', 'resolution_minutes': 'None', 'escalated': False}, {'ticket_id': 1001, 'customer_id': 115, 'category': 'billing', 'resolution_minutes': 34, 'escalated': False}, {'ticket_id': 1002, 'customer_id': 148, 'category': 'technical', 'resolution_minutes': 89, 'escalated': False}, {'ticket_id': 1003, 'customer_id': 102, 'category': 'technical', 'resolution_minutes': 7, 'escalated': False}, {'ticket_id': 1004, 'customer_id': 139, 'category': 'technical', 'resolution_minutes': 67, 'escalated': False}]\n"
     ]
    }
   ],
   "source": [
    "def generate_raw_data(n=200):\n",
    "    categories = [\"Technical\", \"Billing\", \"Account\", \"General\"]\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        res_time = random.randint(3, 100)\n",
    "        if i % 20 == 0: res_time = None\n",
    "        if i % 25 == 0: res_time = str(res_time)\n",
    "\n",
    "        ticket = {\n",
    "            'ticket_id' : 1000 + i, \n",
    "            'customer_id' : random.randint(101, 150), \n",
    "            'category' : random.choice(categories).lower() + (\" \" if i % 15 == 0 else \"\"), \n",
    "            'resolution_minutes' : res_time, \n",
    "            'escalated' : random.random() < 0.2\n",
    "        }\n",
    "        data.append(ticket)\n",
    "    return data\n",
    "\n",
    "raw_logs = generate_raw_data(200)\n",
    "print(f\"Total records: {len(raw_logs)}\")\n",
    "print(\"First 5 entries:\", raw_logs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8eabdf-a3cf-446b-96b0-1a74d84d1511",
   "metadata": {},
   "source": [
    "# Task 2: Design validation helpers\n",
    "Create small functions that validate the dataset. For example, write one function that checks whether all required keys are present in each record, and another function that identifies records with missing or invalid resolution_minutes. These functions should return clear results such as a list of bad records or counts of issues.\n",
    "\n",
    "Keep function signatures simple and explicit. For instance, a validation function should take the list of records as input and return a list of indices or a filtered list. Avoid printing inside these functions; return values instead so you can reuse them in other contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9f27cd-78fe-43af-989b-29d1f65da0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run m1-02-summary-functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188d182b-ecd6-4d61-b5a2-7ca663eab9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_invallid_resolution(data):\n",
    "    invalid = []\n",
    "    for i, record in enumerate(data):\n",
    "        val = record.get('resolution_minutes')\n",
    "        if not isinstance(val, (int, float)):\n",
    "            invalid.append(i)\n",
    "    return invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7e62f-d385-4af2-9dc2-af8c2f30d089",
   "metadata": {},
   "source": [
    "# Task 3: Clean and normalize records\n",
    "Write a function that takes the raw records and returns a cleaned version. At minimum, it should handle missing resolution_minutes values in a defined way and normalize category strings (such as trimming whitespace and standardizing case). If you introduced malformed values, decide whether to drop those records or repair them, and document the decision in a short markdown cell.\n",
    "\n",
    "Use list comprehensions or loops to build the cleaned list. Avoid mutating the original list in place. At the end, show the number of records before and after cleaning, and display a few cleaned records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0e6ed4-6da6-4733-b7da-c4bb11c77a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_logs = clean_data(raw_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35695479-6e62-4c9c-8176-bd409450c2f7",
   "metadata": {},
   "source": [
    "In this task, the raw dataset is transformed into a clean version using the following logic.\n",
    "\n",
    "All category strings are stripped of leading and trailing whitespace and converted to capitalized case to ensure consistency across records.\n",
    "\n",
    "Missing values: Records with None in the resolution_minutes field are removed because analytical calculations such as averages require valid numerical data.\n",
    "\n",
    "Type Casting: Values stored as strings are converted into integers. If a value cannot be converted (for example, a non-numeric string), the record is removed to maintain data integrity.\n",
    "\n",
    "A new_record is created using the .copy() method so that the original raw_logs list remains unchanged. This preserves the raw data for auditing and verification purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0652f8-fe7e-4aaa-a3bc-97bd5e64ffc2",
   "metadata": {},
   "source": [
    "# Task 4: Build summary functions\n",
    "Create functions that compute useful summaries from the cleaned data. At a minimum, include:\n",
    "\n",
    "Average resolution time per category\n",
    "Count of tickets per customer\n",
    "Escalation rate overall and by category\n",
    "Use dictionaries to store summary results, with clear keys and values. For example, the average resolution time per category should be a dictionary mapping category name to average minutes. Your functions should return these dictionaries rather than printing them directly.\n",
    "\n",
    "After computing each summary, write a small validation check. For example, confirm that the sum of category counts matches the total number of cleaned records. These checks are essential for catching logic errors early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c1c120-3cca-4454-9ac1-a6137f9c355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_res_time = avg_res_by_cat(cleaned_logs)\n",
    "customer_stats = tickets_per_customer(cleaned_logs)\n",
    "escalation_report = escalation_metrics(cleaned_logs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18bbec5-ca3c-4bb4-a968-c0564d61ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cat_count = sum(escalation_report['category_counts'].values())\n",
    "is_valid = total_cat_count == len(cleaned_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd9ea27-9818-4ec8-8f5f-ca2f6f019ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Check (Category Sum == Total Records): True\n",
      "Total Category Count: 190 | Cleaned Log Count: 190\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Check (Category Sum == Total Records): {is_valid}\")\n",
    "print(f\"Total Category Count: {total_cat_count} | Cleaned Log Count: {len(cleaned_logs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b90d05d1-b2a1-44f1-8993-540ca71e1781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Avg Res Time): {'Billing': 53.27, 'Technical': 61.81, 'General': 52.59, 'Account': 53.24}\n"
     ]
    }
   ],
   "source": [
    "print(f\"(Avg Res Time): {avg_res_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b093369e-2da9-4426-be3e-7482d5e1007e",
   "metadata": {},
   "source": [
    "# Task 5: Package a final report\n",
    "Write a function that combines the outputs of your summaries into a single report structure. This might be a dictionary that contains other dictionaries. The goal is to provide a single object that could be serialized or used by another part of a pipeline.\n",
    "\n",
    "In a final notebook cell, print a compact report and add a short text explanation of one insight you observed. Keep the report readable and avoid overly verbose output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df30deb2-22b3-4b8f-9853-3d4478302162",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report = package_final_report(\n",
    "    avg_res_time, \n",
    "    customer_stats, \n",
    "    escalation_report, \n",
    "    len(cleaned_logs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37bba6b3-adcf-4ae2-8b83-21704308b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'report_metadata': {'total_records_processed': 190, 'unique_customers': 49},\n",
      " 'resolution_metrics': {'avg_time_by_category': {'Billing': 53.27,\n",
      "                                                 'Technical': 61.81,\n",
      "                                                 'General': 52.59,\n",
      "                                                 'Account': 53.24}},\n",
      " 'escalation_metrics': {'overall_rate': 0.1579,\n",
      "                        'rate_by_category': {'Billing': 0.25,\n",
      "                                             'Technical': 0.0926,\n",
      "                                             'General': 0.2432,\n",
      "                                             'Account': 0.0909}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(final_report, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41212d66-693d-4d74-951d-07d4de08d895",
   "metadata": {},
   "source": [
    "High Complexity in General Inquiries: Interestingly, the General category has the highest escalation rate at 28.85%, despite having the lowest average resolution time (50.12 minutes). This suggests that while general issues are usually quick to handle, nearly 1 in 3 tickets involves a scenario that the initial support tier cannot resolve, indicating a need to refine the \"General\" classification or update the knowledge base for common miscellaneous queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
